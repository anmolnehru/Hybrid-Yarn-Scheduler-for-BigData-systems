2015-11-28 02:18:55,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = anmol-vm1-new/10.0.1.190
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.4.2-SNAPSHOT
STARTUP_MSG:   classpath = /home/hadoop/yarnpp/conf:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/junit-4.8.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/hadoop-auth-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-el-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/hadoop-annotations-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/hadoop-nfs-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/hadoop-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/hadoop-common-2.4.2-SNAPSHOT-tests.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/hadoop-hdfs-2.4.2-SNAPSHOT-tests.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/hadoop-hdfs-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/hadoop-hdfs-nfs-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/zookeeper-3.4.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jackson-xc-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-client-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-api-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-tests-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/hadoop-annotations-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.2-SNAPSHOT-tests.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.4.2-SNAPSHOT.jar:/contrib/capacity-scheduler/*.jar:/home/hadoop/yarnpp/conf:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-examples-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-tests-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-api-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-common-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-internals-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-dag-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-library-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guice-3.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-collections4-4.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-shuffle-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-core-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/jettison-1.3.4.jar:/contrib/capacity-scheduler/*.jar:/home/hadoop/yarnpp/conf:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-examples-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-tests-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-api-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-common-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-internals-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-dag-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-library-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guice-3.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-collections4-4.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-shuffle-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-core-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/jettison-1.3.4.jar:/contrib/capacity-scheduler/*.jar:/home/hadoop/yarnpp/conf:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-examples-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-tests-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-api-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-common-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-internals-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-dag-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-library-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guice-3.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-collections4-4.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-shuffle-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-core-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/jettison-1.3.4.jar
STARTUP_MSG:   build = https://github.com/anmolnehru/838-mercury-final-project.git -r fb7173400094bb0f1c0b5ad847102eb8ae5ecd61; compiled by 'ubuntu' on 2015-11-27T21:58Z
STARTUP_MSG:   java = 1.7.0_85
************************************************************/
2015-11-28 02:18:55,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-11-28 02:18:55,489 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/0/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,489 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/1/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,490 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/2/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,490 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/3/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,490 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/4/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,490 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/5/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,490 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/6/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,491 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/7/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,491 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/8/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,491 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/9/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:55,723 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-28 02:18:56,039 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-11-28 02:18:56,130 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 60 second(s).
2015-11-28 02:18:56,130 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2015-11-28 02:18:56,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is anmol-vm1-new
2015-11-28 02:18:56,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2015-11-28 02:18:56,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2015-11-28 02:18:56,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2015-11-28 02:18:56,245 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-28 02:18:56,250 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2015-11-28 02:18:56,262 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-11-28 02:18:56,265 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2015-11-28 02:18:56,265 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-28 02:18:56,265 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-28 02:18:56,285 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2015-11-28 02:18:56,288 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2015-11-28 02:18:56,288 INFO org.mortbay.log: jetty-6.1.26
2015-11-28 02:18:56,528 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50075
2015-11-28 02:18:56,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2015-11-28 02:18:56,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2015-11-28 02:18:56,590 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-11-28 02:18:56,609 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2015-11-28 02:18:56,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2015-11-28 02:18:56,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2015-11-28 02:18:56,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2015-11-28 02:18:56,718 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/0/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,718 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/1/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,719 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/2/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,719 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/3/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,719 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/4/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,719 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/5/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,719 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/6/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,719 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/7/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,720 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/8/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,720 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/9/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:18:56,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to anmol-vm1-new/10.0.1.190:8020 starting to offer service
2015-11-28 02:18:56,760 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-11-28 02:18:56,761 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2015-11-28 02:18:57,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:18:58,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:18:59,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:00,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:01,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:02,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:03,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:04,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:05,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:06,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:06,936 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:19:12,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:13,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:14,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:15,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:16,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:17,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:18,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:19,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:20,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:21,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:21,951 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:19:27,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:28,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:19:29,581 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2015-11-28 02:19:29,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at anmol-vm1-new/10.0.1.190
************************************************************/
2015-11-28 02:22:10,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = anmol-vm1-new/10.0.1.190
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.4.2-SNAPSHOT
STARTUP_MSG:   classpath = /home/hadoop/yarnpp/conf:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/junit-4.8.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/hadoop-auth-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-el-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/hadoop-annotations-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/hadoop-nfs-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/hadoop-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/common/hadoop-common-2.4.2-SNAPSHOT-tests.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/hadoop-hdfs-2.4.2-SNAPSHOT-tests.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/hadoop-hdfs-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/hdfs/hadoop-hdfs-nfs-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/zookeeper-3.4.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jackson-xc-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-client-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-api-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-tests-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/hadoop-annotations-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.2-SNAPSHOT-tests.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/hadoop-2.4.2-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.4.2-SNAPSHOT.jar:/contrib/capacity-scheduler/*.jar:/home/hadoop/yarnpp/conf:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-examples-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-tests-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-api-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-common-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-internals-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-dag-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-library-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guice-3.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-collections4-4.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-shuffle-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-core-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/jettison-1.3.4.jar:/contrib/capacity-scheduler/*.jar:/home/hadoop/yarnpp/conf:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-examples-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-tests-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-api-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-common-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-internals-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-dag-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-library-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guice-3.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-collections4-4.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-shuffle-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-core-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/jettison-1.3.4.jar:/contrib/capacity-scheduler/*.jar:/home/hadoop/yarnpp/conf:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-mapreduce-examples-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-tests-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-api-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-common-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-internals-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-dag-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/tez-runtime-library-0.4.1-incubating.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guice-3.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/avro-1.7.4.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-collections4-4.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/commons-cli-1.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/snappy-java-1.0.4.1.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-shuffle-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/guava-11.0.2.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/protobuf-java-2.5.0.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-core-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/hadoop-mapreduce-client-common-2.4.2-SNAPSHOT.jar:/home/hadoop/yarnpp/tez-0.4.1-incubating/lib/jettison-1.3.4.jar
STARTUP_MSG:   build = https://github.com/anmolnehru/838-mercury-final-project.git -r fb7173400094bb0f1c0b5ad847102eb8ae5ecd61; compiled by 'ubuntu' on 2015-11-27T21:58Z
STARTUP_MSG:   java = 1.7.0_85
************************************************************/
2015-11-28 02:22:10,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-11-28 02:22:11,090 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/0/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,091 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/1/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,091 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/2/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,091 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/3/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,091 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/4/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,092 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/5/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,092 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/6/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,092 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/7/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,092 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/8/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,092 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/9/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:11,327 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-28 02:22:11,650 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-11-28 02:22:11,742 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 60 second(s).
2015-11-28 02:22:11,742 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2015-11-28 02:22:11,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is anmol-vm1-new
2015-11-28 02:22:11,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2015-11-28 02:22:11,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2015-11-28 02:22:11,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2015-11-28 02:22:11,854 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-28 02:22:11,858 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2015-11-28 02:22:11,870 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-11-28 02:22:11,873 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2015-11-28 02:22:11,873 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-28 02:22:11,873 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-28 02:22:11,893 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2015-11-28 02:22:11,896 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2015-11-28 02:22:11,896 INFO org.mortbay.log: jetty-6.1.26
2015-11-28 02:22:12,141 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50075
2015-11-28 02:22:12,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2015-11-28 02:22:12,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2015-11-28 02:22:12,206 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-11-28 02:22:12,226 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2015-11-28 02:22:12,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2015-11-28 02:22:12,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2015-11-28 02:22:12,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2015-11-28 02:22:12,337 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/0/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,338 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/1/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,338 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/2/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,338 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/3/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,338 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/4/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,338 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/5/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,339 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/6/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,339 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/7/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,339 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/8/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,339 WARN org.apache.hadoop.hdfs.server.common.Util: Path /mnt/data/9/local/hdfs/data should be specified as a URI in configuration files. Please update hdfs configuration.
2015-11-28 02:22:12,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to anmol-vm1-new/10.0.1.190:8020 starting to offer service
2015-11-28 02:22:12,376 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-11-28 02:22:12,378 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2015-11-28 02:22:13,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:14,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:15,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:16,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:17,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:18,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:19,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:20,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:21,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:22,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:22,533 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:22:28,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:29,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:30,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:31,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:32,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:33,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:34,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:35,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:36,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:37,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:37,542 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:22:43,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:44,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:45,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:46,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:47,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:48,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:49,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:50,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:51,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:52,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:52,551 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:22:58,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:22:59,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:00,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:01,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:02,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:03,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:04,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:05,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:06,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:07,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:07,560 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:23:13,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:14,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:15,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:16,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:17,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:18,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:19,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:20,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:21,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:22,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:22,570 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:23:28,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:29,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:30,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:31,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:32,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:33,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:34,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:35,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:36,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:37,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:37,580 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:23:43,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:44,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:45,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:46,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:47,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:48,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:49,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:50,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:51,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:52,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:52,588 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:23:58,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:23:59,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:00,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:01,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:02,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:03,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:04,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:05,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:06,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:07,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:07,597 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:24:13,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:14,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:15,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:16,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:17,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:18,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:19,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:20,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:21,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:22,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:22,608 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:24:28,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:29,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:30,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:31,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:32,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:33,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:34,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:35,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:36,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:37,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:37,616 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:24:43,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:44,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:45,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:46,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:47,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:48,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:49,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:50,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:51,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:52,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:52,627 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:24:58,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:24:59,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:00,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:01,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:02,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:03,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:04,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:05,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:06,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:07,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:07,637 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:25:13,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:14,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:15,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:16,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:17,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:18,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:19,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:20,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:21,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:22,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:22,646 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:25:28,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:29,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:30,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:31,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:32,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:33,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:34,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:35,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:36,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:37,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:37,656 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:25:43,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:44,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:45,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:46,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:47,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:48,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:49,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:50,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:51,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:52,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:52,664 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:25:58,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:25:59,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:00,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:01,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:02,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:03,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:04,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:05,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:06,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:07,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:07,676 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:26:13,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:14,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:15,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:16,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:17,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:18,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:19,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:20,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:21,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:22,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:22,690 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:26:28,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:29,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:30,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:31,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:32,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:33,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:34,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:35,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:36,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:37,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:37,704 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:26:43,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:44,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:45,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:46,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:47,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:48,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:49,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:50,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:51,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:52,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:52,722 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:26:58,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:26:59,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:00,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:01,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:02,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:03,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:04,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:05,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:06,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:07,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:07,732 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:27:13,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:14,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:15,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:16,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:17,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:18,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:19,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:20,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:21,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:22,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:22,751 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:27:28,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:29,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:30,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:31,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:32,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:33,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:34,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:35,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:36,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:37,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:37,761 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:27:43,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:44,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:45,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:46,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:47,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:48,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:49,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:50,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:51,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:52,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:52,769 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:27:58,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:27:59,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:00,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:01,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:02,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:03,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:04,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:05,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:06,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:07,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:07,777 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:28:13,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:14,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:15,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:16,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:17,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:18,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:19,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:20,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:21,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:22,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:22,789 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:28:28,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:29,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:30,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:31,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:32,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:33,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:34,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:35,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:36,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:37,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:37,797 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:28:43,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:44,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:45,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:46,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:47,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:48,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:49,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:50,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:51,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:52,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:52,806 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:28:58,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:28:59,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:00,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:01,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:02,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:03,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:04,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:05,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:06,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:07,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:07,814 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:29:13,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:14,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:15,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:16,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:17,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:18,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:19,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:20,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:21,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:22,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:22,823 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:29:28,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:29,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:30,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:31,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:32,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:33,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:34,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:35,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:36,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:37,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:37,831 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:29:43,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:44,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:45,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:46,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:47,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:48,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:49,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:50,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:51,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:52,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:52,840 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:29:58,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:29:59,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:00,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:01,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:02,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:03,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:04,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:05,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:06,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:07,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:07,849 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:30:13,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:14,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:15,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:16,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:17,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:18,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:19,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:20,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:21,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:22,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:22,857 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:30:28,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:29,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:30,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:31,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:32,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:33,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:34,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:35,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:36,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:37,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:37,866 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:30:43,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:44,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:45,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:46,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:47,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:48,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:49,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:50,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:51,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:52,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:52,874 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:30:58,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:30:59,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:00,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:01,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:02,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:03,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:04,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:05,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:06,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:07,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:07,882 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:31:13,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:14,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:15,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:16,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:17,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:18,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:19,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:20,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:21,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:22,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:22,891 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:31:28,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:29,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:30,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:31,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:32,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:33,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:34,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:35,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:36,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:37,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:37,899 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: anmol-vm1-new/10.0.1.190:8020
2015-11-28 02:31:43,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:44,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:45,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:46,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:47,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:48,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:49,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-11-28 02:31:50,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: anmol-vm1-new/10.0.1.190:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
